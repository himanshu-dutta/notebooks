{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders\n",
    "from fastai.learner import Learner\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.vision.all import torch, tensor, untar_data, Image, URLs, DataLoader, Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param(size):\n",
    "    return torch.randn(size).requires_grad_()"
   ]
  },
  {
   "source": [
    "# Layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_, out_):\n",
    "        self.w = init_param((in_, out_))\n",
    "        self.b = init_param(1)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x @ self.w + self.b\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return [self.w, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return torch.where(x > 0.0, x, torch.zeros_like(x))"
   ]
  },
  {
   "source": [
    "# Sequential API"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential:\n",
    "    def __init__(self, *args):\n",
    "        self.layers = list(args)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y = x\n",
    "        for lay in self.layers:\n",
    "            y = lay(y)\n",
    "        return y\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        p_ = []\n",
    "\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, \"params\"):\n",
    "                p_ += layer.params\n",
    "\n",
    "        return p_"
   ]
  },
  {
   "source": [
    "# Optimizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param.data -= param.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            param.grad = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(preds, targets):\n",
    "    preds = preds.sigmoid()\n",
    "    return torch.where(targets == 1, 1 - preds, preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(preds, targets):\n",
    "    preds = preds.sigmoid()\n",
    "    return ((preds > 0.5) == targets).float().mean().item()"
   ]
  },
  {
   "source": [
    "# Trainer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, train_dl, val_dl, model, lr, optim_cls, loss_fn):\n",
    "        self.train_dl = train_dl\n",
    "        self.val_dl = val_dl\n",
    "        self.model = model\n",
    "        self.optim = optim_cls(self.model.params, lr)\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def _calc_grad(self, x, y):\n",
    "        out = self.model(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "        loss.backward()\n",
    "\n",
    "        return loss.detach().cpu().item()\n",
    "\n",
    "    def _train_step(self, *args, **kwargs):\n",
    "        losses = []\n",
    "        for x, y in self.train_dl:\n",
    "            losses.append(self._calc_grad(x, y))\n",
    "            self.optim.step()\n",
    "            self.optim.zero_grad()\n",
    "\n",
    "        return tensor(losses).mean().item()\n",
    "\n",
    "    def _val_step(self, *args, **kwargs):\n",
    "        preds = []\n",
    "        targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in self.val_dl:\n",
    "                preds.append(self.model(x))\n",
    "                targets.append(y)\n",
    "\n",
    "        preds = torch.cat(preds).float()\n",
    "        targets = torch.cat(targets).float()\n",
    "\n",
    "        return (\n",
    "            self.loss_fn(preds, targets).item(),\n",
    "            acc(preds.reshape(-1), targets.reshape(-1)),\n",
    "        )\n",
    "\n",
    "    def fit(self, epochs):\n",
    "        for eph in range(epochs):\n",
    "            train_loss = self._train_step()\n",
    "            val_loss, val_acc = self._val_step()\n",
    "            print(\n",
    "                f\"Epoch [{eph}]: train_loss: {round(train_loss, 4)}, val_loss: {round(val_loss, 4)}, val_acc:{round(val_acc, 4)}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "print(path)\n",
    "\n",
    "Path.BASE_PATH = path\n",
    "\n",
    "# load and convert the images to float tensors\n",
    "train_3 = (\n",
    "    torch.stack(\n",
    "        [tensor(Image.open(pth)) for pth in (path / \"train\" / \"3\").ls()]\n",
    "    ).float()\n",
    "    / 255\n",
    ")\n",
    "train_7 = (\n",
    "    torch.stack(\n",
    "        [tensor(Image.open(pth)) for pth in (path / \"train\" / \"7\").ls()]\n",
    "    ).float()\n",
    "    / 255\n",
    ")\n",
    "\n",
    "val_3 = (\n",
    "    torch.stack(\n",
    "        [tensor(Image.open(pth)) for pth in (path / \"valid\" / \"3\").ls()]\n",
    "    ).float()\n",
    "    / 255\n",
    ")\n",
    "val_7 = (\n",
    "    torch.stack(\n",
    "        [tensor(Image.open(pth)) for pth in (path / \"valid\" / \"7\").ls()]\n",
    "    ).float()\n",
    "    / 255\n",
    ")\n",
    "\n",
    "# training and validation dataset\n",
    "train_X = torch.cat([train_3, train_7]).reshape(-1, 28 * 28)\n",
    "train_y = tensor([1.0] * len(train_3) + [0.0] * len(train_7))\n",
    "\n",
    "val_X = torch.cat([val_3, val_7]).reshape(-1, 28 * 28)\n",
    "val_y = tensor([1.0] * len(val_3) + [0.0] * len(val_7))\n",
    "\n",
    "# dataloaders\n",
    "train_dl = DataLoader(\n",
    "    list(zip(train_X, train_y)), bs=16, num_workers=4, shuffle=True\n",
    ")\n",
    "val_dl = DataLoader(list(zip(val_X, val_y)), bs=32, num_workers=4)\n",
    "\n",
    "dls = DataLoaders(train_dl, val_dl)\n",
    "\n",
    "model = Sequential(\n",
    "    Linear(28 * 28, 32),\n",
    "    ReLU(),\n",
    "    Linear(32, 64),\n",
    "    ReLU(),\n",
    "    Linear(64, 1),\n",
    ")\n",
    "\n",
    "lrn = Trainer(train_dl, val_dl, model, 9e-2, SGD, mnist_loss)\n",
    "lrn.fit(40)"
   ]
  }
 ]
}